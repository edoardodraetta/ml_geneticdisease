{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b0e21-620a-43e6-8971-6fe19bdc7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 85)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff02ec4-e455-4202-950e-d20268d958eb",
   "metadata": {},
   "source": [
    "# Random Forest Evaluation with Nested Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4488c708-9568-49cc-8630-dc45267483b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dc909f-32a9-4e03-acb5-39dc0c2123d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data from CSV (NEW DATA, NOT SCALED)\n",
    "df = pd.read_csv(\"../data/abnormal_writeout_noscale.data.csv\", index_col=0)\n",
    "\n",
    "# trascurare da ACC a UVM\n",
    "start_drop = df.columns.get_loc(\"ACC\")\n",
    "end_drop = df.columns.get_loc(\"UVM\")\n",
    "cols = np.arange(start_drop, end_drop + 1)\n",
    "df.drop(df.columns[cols], axis=1, inplace=True)\n",
    "\n",
    "# trascurare alcune colonne\n",
    "df.drop(\"TTT_freq\", axis=1, inplace=True)\n",
    "df.drop(\"oldest_phylostratum_factor\", axis=1, inplace=True)\n",
    "\n",
    "# Drop NaNs\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Sort features\n",
    "resp = df[\"response\"]\n",
    "occ = df[\"occ_total_sum\"]\n",
    "age = df[\"oldest_phylostratum\"]\n",
    "conf = df.drop(labels=[\"response\", \"occ_total_sum\", \"oldest_phylostratum\"], axis=1)\n",
    "\n",
    "# Collect Features and Labels\n",
    "features_df = pd.DataFrame()\n",
    "features_df[\"occ_total_sum\"] = occ\n",
    "features_df[\"oldest_phylostratum\"] = age\n",
    "features_df = pd.concat([features_df, conf], axis=1)\n",
    "\n",
    "X = features_df.to_numpy()\n",
    "y = df[\"response\"].to_numpy()\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4534675-2085-40b9-8621-a2535db13986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e17169f-778b-4c26-819f-5f6df2474846",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "***\n",
    "## Custom PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159241f-dd12-47cd-923e-e3e165b04c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Columns of confounder variables (highly colinear)\n",
    "conf_index = 2\n",
    "conf_cols = np.arange(2, X.shape[1])\n",
    "\n",
    "\n",
    "class ConfounderPCA(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" \n",
    "    Custom PCA transformer for this dataset.\n",
    "    Applies PCA only to the many collinear confounder \n",
    "    variables.\n",
    "    \n",
    "    cols - columns to which PCA will be applied.\n",
    "    \n",
    "    n_components - same as with the \"vanilla\" PCA. \n",
    "        If 0 < n_components < 1, select the number of \n",
    "        components such that the amount of variance that \n",
    "        needs to be explained is greater than the \n",
    "        percentage specified by n_components.\n",
    "        \n",
    "    apply_PCA - if false, simply returns the untransformed data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cols, n_components=None, apply_PCA=True):\n",
    "        self.n_components = n_components\n",
    "        self.apply_PCA = apply_PCA\n",
    "        self.cols = cols\n",
    "        if self.apply_PCA:\n",
    "            self.pca = PCA(n_components=self.n_components)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.apply_PCA:\n",
    "            self.pca.fit(X[:, self.cols])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if self.apply_PCA:\n",
    "            X_pca = self.pca.transform(X[:, self.cols])\n",
    "            return np.c_[X[:, :2], X_pca]\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "\n",
    "sns.heatmap(pd.DataFrame(ConfounderPCA(cols=np.arange(2, X.shape[1])).fit_transform(StandardScaler().fit_transform(X))).corr())\n",
    "plt.title(\"Correlation Matrix after PCA\")\n",
    "plt.show()\n",
    "\n",
    "print(X.shape[1], \"total features.\")\n",
    "print(\"Confounder columns start from index\", conf_index, \"of feature matrix.\")\n",
    "print(\"Non-counfounders:\", features_df.iloc[:, 0:conf_index].columns.tolist())\n",
    "\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7336e89-6dc8-4d37-b71e-0b2849e90d6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## The Model and its Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3ea98-47ac-44e6-bb0a-6a63dfc6b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'rf__max_depth': [None, 10, 20, 30],\n",
    "    \"rf__min_samples_leaf\": [1, 2, 5, 10, 20,],\n",
    "    \"rf__min_samples_split\": [2, 5, 10, 20],\n",
    "    \"rf__max_features\": [None, \"sqrt\"],\n",
    "    \"rf__n_estimators\": [100, 300, 1000],\n",
    "    \"pca__apply_PCA\": [False, True],\n",
    "    \"pca__n_components\": [0.01, 0.5, 0.95, None],\n",
    "}\n",
    "rf_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    (\"pca\", ConfounderPCA(cols=np.arange(2, X.shape[1]))), \n",
    "    (\"rf\", BalancedRandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40551323-45b7-4e99-b08b-717fe895315b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e90e13-1b2c-4de0-ac6f-92a2362b53ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.exceptions import ConvergenceWarning, FitFailedWarning\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "k_outer = 5\n",
    "k_inner = 3\n",
    "cv_outer = KFold(n_splits=k_outer, shuffle=True, random_state=1)\n",
    "\n",
    "# To store results\n",
    "roc_results = list()\n",
    "# auprc_results = list()\n",
    "# prec_results = list()\n",
    "# rec_results = list()\n",
    "# f1_results = list()\n",
    "found_params = list()\n",
    "\n",
    "print(\"OUTER CV | INNER CV | CHOSEN PARAMS\")\n",
    "\n",
    "for i, (train_ix, test_ix) in enumerate(cv_outer.split(X)):\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "\n",
    "    # configure the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=k_inner, shuffle=True, random_state=i) # Deterministic but changing RS\n",
    "\n",
    "    with ignore_warnings(category=[ConvergenceWarning, FitFailedWarning]):\n",
    "        # define search\n",
    "        search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, scoring=\"roc_auc\", cv=cv_inner)\n",
    "        # execute search\n",
    "        result = search.fit(X_train, y_train)\n",
    "        \n",
    "    # get the best performing model fit on the whole training set\n",
    "    best_model = result.best_estimator_\n",
    "\n",
    "    # evaluate model on the hold out dataset\n",
    "    # yhat = best_model.predict(X_test)\n",
    "    yhat = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # evaluate the model\n",
    "    roc_auc = roc_auc_score(y_test, yhat)\n",
    "    \n",
    "    # store the result\n",
    "    roc_results.append(roc_auc)\n",
    "    # auprc_results.append(auprc(y_test, yhat))\n",
    "    # prec_results.append(precision_score(y_test, yhat))11\n",
    "    # rec_results.append(recall_score(y_test, yhat))\n",
    "    # f1_results.append(f1_score(y_test, yhat))\n",
    "    found_params.append(result.best_params_)\n",
    "\n",
    "    # report progress\n",
    "    print(\"roc-auc=%.3f, est=%.3f, params=%s\" % (roc_auc, result.best_score_, result.best_params_))\n",
    "\n",
    "# summarize the estimated performance of the model\n",
    "print(\"ROC-AUC: %.3f (std = %.3f)\" % (np.mean(roc_results), np.std(roc_results)))\n",
    "print(\"(other scores stored in ncv_df)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd7c0a-39d1-426a-ba28-cdc4d668e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncv_df = pd.DataFrame()\n",
    "ncv_df[\"ROC-AUC\"] = roc_results\n",
    "# ncv_df[\"AUPRC\"] = auprc_results\n",
    "# ncv_df[\"Precision\"] = prec_results\n",
    "# ncv_df[\"Recall\"] = rec_results\n",
    "# ncv_df[\"f1-score\"] = f1_results\n",
    "ncv_df = pd.concat([ncv_df, pd.DataFrame(found_params)], axis=1)\n",
    "ncv_df.to_csv(\"./data/rf_ncv.csv\")\n",
    "ncv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ae24c-6a09-4055-b348-66b56f3b742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncv_df[\"ROC-AUC\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5063307-92d5-4295-beda-718832f925c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Random Forest - Scoring on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de55e4f-8de5-442f-827d-793b84bf0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search object\n",
    "gscv = GridSearchCV(\n",
    "    estimator=rf_clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring=\"roc_auc\", \n",
    ")\n",
    "\n",
    "# Search\n",
    "gscv_result = gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236b861-6801-46e4-9ad3-543225a03833",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gscv_result.best_estimator_\n",
    "print(\"Best Params:\")\n",
    "print(gscv_result.best_params_)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb0bbbb-9b02-46ec-b2cb-f2b58cc19310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2bb4fa-7d2a-44c2-a9c7-df2273e9e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d18fc-0bd4-4f6d-b95a-11e9682ed32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
