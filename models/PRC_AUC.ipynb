{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e196a62c-5d8c-473a-a728-deb338912141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cdf53375-3716-4092-b71b-7b9ff773b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def fetch_data(drop_some=True):\n",
    "    df = pd.read_csv(\"../data/abnormal_writeout.data.csv\")\n",
    "    if drop_some:\n",
    "        # trascurare da ACC a UVM\n",
    "        start_drop = df.columns.get_loc(\"ACC\")\n",
    "        end_drop = df.columns.get_loc(\"UVM\")\n",
    "        cols = np.arange(start_drop, end_drop + 1)\n",
    "        df.drop(df.columns[cols], axis=1, inplace=True)\n",
    "        # trascurare old_phylo_factor e la prima colonna\n",
    "        # df.drop(\"TTT_freq\", axis=1, inplace=True)\n",
    "        df.drop(\"oldest_phylostratum_factor\", axis=1, inplace=True)\n",
    "        df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "        # Drop NaNs\n",
    "        df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def separate_data(df):\n",
    "    resp = df[\"response\"].to_numpy()\n",
    "    occ = df[\"occ_total_sum\"]\n",
    "    age = df[\"oldest_phylostratum\"].to_numpy()\n",
    "    conf = df.drop(labels=[\"response\", \"occ_total_sum\", \"oldest_phylostratum\"], axis=1).to_numpy()\n",
    "    return occ, age, conf, resp\n",
    "\n",
    "\n",
    "def get_PCA(X, expl_var=0.95, plot=False):\n",
    "    # Fit a PCA\n",
    "    pca_test = PCA()\n",
    "    pca_test.fit(X)\n",
    "    cumsum = np.cumsum(pca_test.explained_variance_ratio_)\n",
    "    d = np.argmax(cumsum >= expl_var) + 1\n",
    "    # Apply PCA with d components\n",
    "    pca_apply = PCA(n_components=d)\n",
    "    X_PCA = pca_apply.fit_transform(X)\n",
    "    print(\"Using {} principal components.\".format(d))\n",
    "    print(f\"Reduced features by {(784-d)/784*100:.2f}%.\")\n",
    "    if plot == True:\n",
    "        sns.heatmap(pd.DataFrame(X_PCA).corr())\n",
    "        plt.show()\n",
    "    return X_PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7cfd12-a7e8-45fc-a0f1-1290192e7ede",
   "metadata": {},
   "source": [
    "# Valutazione dell'area sotto la curva PR per modelli logistici e RF bilanciati e non"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68163b08-1b93-4cb3-9ad0-3c4bddc87300",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "* Incoming datafile has been previously standardized.\n",
    "* Columns from \"ACC\" to \"UVM\" are subsequently dropped.\n",
    "* Column \"oldest_phylostratum_factor\" is dropped.\n",
    "* PCA is applied to the confounding variables (all except occ_total_sum and olders_phylostratum) and PCs are kept only up to 95% explained variance.\n",
    "* An 80:20 train-test split is applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d26201b-4a7c-4669-b3ed-1a23da09aff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 47 principal components.\n",
      "Reduced features by 94.01%.\n",
      "Feature matrix shape: (14536, 49) (3634, 49)\n",
      "Label matrix shape: (14536,) (3634,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = fetch_data()\n",
    "X_ots, X_age, X_conf, Y = separate_data(df)\n",
    "X_conf_pca = get_PCA(X_conf)\n",
    "\n",
    "# All features, confounders with PCA\n",
    "X = np.c_[X_ots, X_age, X_conf_pca]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Feature matrix shape:\", X_train.shape, X_test.shape)\n",
    "print(\"Label matrix shape:\", y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f881746-b6de-4073-81c2-6507afcd9a30",
   "metadata": {},
   "source": [
    "## Define a Custom PRC-AUC Metric\n",
    "\n",
    "The following cell uses an sklearn wrapper api called `make_scorer` to create a cv-compatible score from a user-defined callable function.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71d18501-b3de-4157-b3aa-8fc9c3d5c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, make_scorer, precision_recall_curve\n",
    "\n",
    "\n",
    "def auprc(y_true, y_scores, **kwargs):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "    # result is sum of the areas under each curve\n",
    "    return auc(thresholds, precisions[:-1]) + auc(thresholds, recalls[:-1])\n",
    "\n",
    "\n",
    "# Create my custom scorer using a wrapper object\n",
    "auprc_score = make_scorer(auprc, needs_proba=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce68d8e-12c5-4d18-a73b-f2bad52ebecc",
   "metadata": {},
   "source": [
    "## K-Fold Cross-Validation \n",
    "\n",
    "The following cell iterates through a selection of models and computes 10-fold cross-validation for each of the following metrics:\n",
    "* ROC-AUC\n",
    "* Precision\n",
    "* Recall\n",
    "* f1\n",
    "* AUPRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5928d551-0295-4449-82e2-4ac85ceb2f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "ROC-AUC : 0.6610 +/- 0.0125\n",
      "Precision : 0.5651 +/- 0.1113\n",
      "Recall : 0.0535 +/- 0.0128\n",
      "f1-score : 0.0976 +/- 0.0226\n",
      "AUPRC : 0.6930 +/- 0.0555\n",
      "\n",
      "Balanced Logistic Regression\n",
      "ROC-AUC : 0.6622 +/- 0.0124\n",
      "Precision : 0.3131 +/- 0.0096\n",
      "Recall : 0.6275 +/- 0.0190\n",
      "f1-score : 0.4177 +/- 0.0122\n",
      "AUPRC : 0.7578 +/- 0.0594\n",
      "\n",
      "Random Forest\n",
      "ROC-AUC : 0.6463 +/- 0.0077\n",
      "Precision : 0.6194 +/- 0.1089\n",
      "Recall : 0.0340 +/- 0.0113\n",
      "f1-score : 0.0643 +/- 0.0204\n",
      "AUPRC : 0.4796 +/- 0.0419\n",
      "\n",
      "Balanced Random Forest\n",
      "ROC-AUC : 0.6692 +/- 0.0113\n",
      "Precision : 0.3264 +/- 0.0074\n",
      "Recall : 0.6001 +/- 0.0215\n",
      "f1-score : 0.4227 +/- 0.0108\n",
      "AUPRC : 0.5378 +/- 0.0749\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "    \"Balanced Logistic Regression\": LogisticRegression(max_iter=500, class_weight=\"balanced\"),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n",
    "    \"Balanced Random Forest\": BalancedRandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n",
    "}\n",
    "\n",
    "my_metrics = {\n",
    "    \"ROC-AUC\": \"roc_auc\",\n",
    "    \"Precision\": \"precision\",\n",
    "    \"Recall\": \"recall\",\n",
    "    \"f1-score\": \"f1\",\n",
    "    \"AUPRC\": make_scorer(auprc, needs_proba=True,),  # custom: area under precision-recall-curve\n",
    "}\n",
    "\n",
    "\n",
    "lr_df = pd.DataFrame()\n",
    "blr_df = pd.DataFrame()\n",
    "rf_df = pd.DataFrame()\n",
    "brf_df = pd.DataFrame()\n",
    "\n",
    "frames = [lr_df, blr_df, rf_df, brf_df]\n",
    "for i, model_name in enumerate(models):\n",
    "    print(model_name)\n",
    "    frame = frames[i]\n",
    "    for score_name in my_metrics:\n",
    "        cvs = cross_val_score(models[model_name], X_train, y_train, scoring=my_metrics[score_name], cv=10)\n",
    "        frame[score_name] = cvs\n",
    "        print(score_name + f\" : {cvs.mean():.4f} +/- {cvs.std():.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4ca2529-0ec6-46d4-af01-706fc3590289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.655552</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.060790</td>\n",
       "      <td>0.110497</td>\n",
       "      <td>0.655936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.684893</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.051672</td>\n",
       "      <td>0.094183</td>\n",
       "      <td>0.653916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.657705</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>0.101983</td>\n",
       "      <td>0.675669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.677822</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.077562</td>\n",
       "      <td>0.627465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.663989</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.829294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.669964</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.084270</td>\n",
       "      <td>0.654810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.642768</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.045593</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.683869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.656565</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.060790</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.741363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.649480</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.051672</td>\n",
       "      <td>0.093923</td>\n",
       "      <td>0.686393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.650897</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.036474</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.721159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROC-AUC  Precision    Recall  f1-score     AUPRC\n",
       "0  0.655552   0.606061  0.060790  0.110497  0.655936\n",
       "1  0.684893   0.531250  0.051672  0.094183  0.653916\n",
       "2  0.657705   0.750000  0.054711  0.101983  0.675669\n",
       "3  0.677822   0.437500  0.042553  0.077562  0.627465\n",
       "4  0.663989   0.717949  0.085106  0.152174  0.829294\n",
       "5  0.669964   0.576923  0.045455  0.084270  0.654810\n",
       "6  0.642768   0.483871  0.045593  0.083333  0.683869\n",
       "7  0.656565   0.645161  0.060790  0.111111  0.741363\n",
       "8  0.649480   0.515152  0.051672  0.093923  0.686393\n",
       "9  0.650897   0.387097  0.036474  0.066667  0.721159"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6d90f97-a91f-4260-982d-7577e5367d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC      0.660963\n",
      "Precision    0.565096\n",
      "Recall       0.053482\n",
      "f1-score     0.097570\n",
      "AUPRC        0.692987\n",
      "dtype: float64\n",
      "\n",
      "ROC-AUC      0.004177\n",
      "Precision    0.037116\n",
      "Recall       0.004282\n",
      "f1-score     0.007536\n",
      "AUPRC        0.018496\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(lr_df.mean())\n",
    "print()\n",
    "print(lr_df.sem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52fbdfdc-0f15-4c7e-a0d0-61600d8eb2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC      0.662204\n",
      "Precision    0.313075\n",
      "Recall       0.627467\n",
      "f1-score     0.417696\n",
      "AUPRC        0.757813\n",
      "dtype: float64\n",
      "\n",
      "ROC-AUC      0.004133\n",
      "Precision    0.003200\n",
      "Recall       0.006325\n",
      "f1-score     0.004083\n",
      "AUPRC        0.019808\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(blr_df.mean())\n",
    "print()\n",
    "print(blr_df.sem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0cabcde3-727f-41cf-9f21-ada00d00eba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC      0.646292\n",
      "Precision    0.619411\n",
      "Recall       0.034037\n",
      "f1-score     0.064258\n",
      "AUPRC        0.479602\n",
      "dtype: float64\n",
      "\n",
      "ROC-AUC      0.002552\n",
      "Precision    0.036289\n",
      "Recall       0.003761\n",
      "f1-score     0.006806\n",
      "AUPRC        0.013982\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(rf_df.mean())\n",
    "print()\n",
    "print(rf_df.sem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21e92ea5-66e6-4768-9737-1b4d278a5e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC      0.669226\n",
      "Precision    0.326356\n",
      "Recall       0.600121\n",
      "f1-score     0.422738\n",
      "AUPRC        0.537811\n",
      "dtype: float64\n",
      "\n",
      "ROC-AUC      0.003758\n",
      "Precision    0.002458\n",
      "Recall       0.007171\n",
      "f1-score     0.003601\n",
      "AUPRC        0.024952\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(brf_df.mean())\n",
    "print()\n",
    "print(brf_df.sem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae619b06-081b-4928-8988-ca1ab45e5379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-2.392015207883834, pvalue=0.027879820142883077)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "A = lr_df.AUPRC.to_numpy()\n",
    "B = blr_df.AUPRC.to_numpy()\n",
    "\n",
    "print(ttest_ind(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2bcda4d7-27a8-4ce1-b5a1-ecaf27b4d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df.to_csv(\"./data/lr_scores_df\", index=None)\n",
    "blr_df.to_csv(\"./data/blr_scores_df\", index=None)\n",
    "rf_df.to_csv(\"./data/rf_scores_df\", index=None)\n",
    "brf_df.to_csv(\"./data/brf_scores_df\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc97ef8-5220-4a93-ae5f-5b0976a11f28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_venv]",
   "language": "python",
   "name": "conda-env-ml_venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
